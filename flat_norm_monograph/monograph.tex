\documentclass[]{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[mathscr]{euscript}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{example}{Example}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{remark}{Remark}[section]

%opening
\title{Flat Norm Monograph}
\author{Curtis Michels \and Kevin Vixie}

\begin{document}

\maketitle

\begin{abstract}
An intuitive explanation of GMT and the Flat Norm.
\end{abstract}

\section{Introduction}

\section{Applied GMT}

\subsection{Measure Theory}

Mathematics is (at least in part) an exploration of spaces. We look at interesting structures and try to classify them to the best of our ability (when are two instances the same, when are they different, etc.) a more precise definition of what we mean when we say ``space" in a mathematical sense follows:

\begin{definition}[Space]
A space is a set possibly equipped with additional structure, often written as a tuple. The simplest example of a space is merely a set by itself.
\end{definition}

\begin{example}
A metric space $X = (\Omega,d)$ is a set $\Omega$ (whose elements are often called points) together with a distance function $d:\Omega^2 \to \mathbb{R}$ that tells us the distance between any two points in $\Omega$. To recover our intuition surrounding distance, we require $d$ satisfy the following for all points $x,y,z \in \Omega$:

\begin{enumerate}
\item The distance from a point to itself is $0$

$d(x,x) = 0$
\item The distance between two distinct points is always positive

if $x \neq y$ then $d(x,y) > 0$
\item The distance from $x$ to $y$ is always the same as the distance from $y$ to $x$:

$d(x,y) = d(y,x)$
\item The distance to go directly from $x$ to $y$ is less than or equal to the distance from $x$ to an intermediate point $z$ plus then the rest of the distance $z$ to $y$.

$d(x,y) \leq d(x,z) + d(z,y)$
\end{enumerate}
\end{example}

\begin{remark}
Condition 2 is often referred to as ``positvity", condition 3 is ``symmetry" and condition 4 is called the ``triangle inequality"
\end{remark}

\begin{remark}
Even if a space $X$ has additional structure, when we speak of ``the elements of a space $X$" we are referring to the elements of the set $\Omega$ which underlies the space.
\end{remark}

Suppose we have a space $X$, and we would like some way to assign notions of length, area, or volume to the subsets of $X$. Denote the set of all subsets of $X$ by $2^X$. We would like to then develop a theory that yields useful theorems for a function $\mu:2^X \to [0,\infty]$ which takes in a subset of $X$ and assigns it to a nonnegative extended real number (possibly infinity). 

\begin{example}
Let $X = (\mathbb{R}^2,d)$ be the two dimensional Euclidean metric space where for two points $x = (x_1,x_2)$, and $y = (y_1,y_2) \in \mathbb{R}^2$ we have the Euclidean metric $d(x,y) = \sqrt{(x_1-y_1)^2+(x_2-y_2)^2}$. Think about how we might assign areas to possible subsets of $X$, like the open balls of radius $r$ centered at the origin $B(0,r) := \{x = (x_1,x_2) : x_1^2+x_2^2 < r^2\}$ and other geometric shapes, without needing to specify them all by hand. i.e. we want a function that will tell us the area of \textbf{any} set. This is the problem we are trying to solve.
\end{example}

The right place to look for such functions is measure theory, in particular the notion of a so-called \textbf{outer measure} will be useful to us. 

\begin{definition}[Outer Measure]
Let $X$ be any space. A function $\mu:2^X \to [0,\infty]$ is called a ``outer measure on $X$" if:

\begin{enumerate}
\item The measure of the empty set is 0

$\mu(\emptyset) = 0$
\item If $A$ is a subset of $B$ then the measure of $A$ is less than or equal to the measure of $B$

$A \subseteq B \implies \mu(A) \leq \mu(B)$
\item If we have a sequence of subsets of $X$ then the measure of their union is less than or equal to the sum of their measures

$A_1,A_2, \ldots \subseteq X \implies \mu\left(\bigcup\limits_{j=1}^\infty A_j \right) \leq \sum\limits_{j=1}^\infty \mu (A_j)$
\end{enumerate}
\end{definition}

\begin{remark}
Condition 2 is sometimes referred to as ``monotone" and condition 3 ``subadditive"
\end{remark}

\begin{remark}
Note that for some measures and choice of sets condition 3 may say nothing more than $\infty \leq \infty$. No special care with regards to convergence is required to talk about the sum, since we are adding non-negative numbers up. It will either be finite or $\infty$, there is no oscillation to worry about. 
\end{remark}

In working with the above definition for some time, we may recognize that there are certain subsets of a given space that are ``nicer" in a sense to work with, that obey a deeper intuition. The following definition is due to Carath\'eodory who developed a way to identify these so-called measurable sets.

\begin{definition}
Let $\mu$ be a outer measure on $X$. Then a subset $A \subseteq X$ is ``$\mu$-measurable if it reasonably ``cuts" every other set. To be precise, for every set $B \subseteq X$ we must have:

\begin{align*}
\mu(B) = \mu(B \setminus A) + \mu(B \cap A)
\end{align*}
\end{definition}

The above says that a set $A$ is measurable if for every set $B$, the measure of the piece of $A$ in $B$ plus the measure of the chunk of $B$ without $A$ recovers the entire measure of $B$. You may think this definition a bit strange, and it may be difficult to think of measures on spaces and sets within them that do not have this property. And indeed, even the proof that sets that are not measurable exist in simple spaces (like the real number line equipped with standard calculus tools) is challenging and difficult. However, such non-measurable sets exist there, and furthermore are fundamental in a sense, as it may be proven that every reasonable measure of length on said number line yields sets that are not measurable. 

It has yet to be seen why this is a good definition, but soon enough this will become clear. 

\begin{remark}
For any space $X$ and outer measure $\mu$ on $X$, it is easy to check from the definition above:
\begin{enumerate}
\item The empty set and the entire space $\emptyset$, $X$ are always $\mu$-measurable.
\item All null sets (sets for which $\mu(A) = 0$) are $\mu$-measurable.
\item If $A$ is $\mu$-measurable then $X \setminus A$ is also $\mu$-measurable.
\end{enumerate}
\end{remark}

\begin{definition}
A family (set of sets) $\mathscr{A}$ of subsets of a space $X$ is called a $\sigma$-algebra if:

\begin{enumerate}
\item $\emptyset, X \in \mathscr{A}$
\item If $A \in \mathscr{A}$ then so to is its relative complement $X \setminus A \in \mathscr{A}$
\item Any sequence $A_1, A_2, \ldots \in \mathscr{A}$ is closed in $\mathscr{A}$ under unions $\bigcup\limits_{j=1}^\infty A_j \in \mathscr{A}$
\end{enumerate}
\end{definition}

\begin{remark}
Although it is not part of the definition, the 3 conditions specified imply that if $A_1, A_2, \ldots \in \mathscr{A}$ then so too is their intersection $\bigcap\limits_{j = 1}^\infty A_j \in \mathscr{A}$. This follows from De Morgan's laws regarding unions and compliments. 
\end{remark}

From the definitions, it is easily checked that given a measure $\mu$ on $X$ the collection of all $\mu$-measurable sets form a $\sigma$-algebra.

\begin{remark}
In probability and statistics, very often it is common to instead start with a $\sigma$-algebra $M$ on a space $X$ and then given a measure $\mu$, to refer to all sets in $M$ as being measurable.
\end{remark}

\begin{theorem}[Existence of a smallest $\sigma$-algebra]
Let $A$ be a (possibly uncountable) collection of subsets in $X$. Then there exists a ``smallest" sigma algebra $\mathscr{A}$ that contains all of the sets in $A$. 

\begin{proof}
Consider the set of all $\sigma$-algebras that contain the subets of $A$, indexed by some possibly uncountable set $I$, denoted $\{\mathscr{A}_\alpha\}_{\alpha \in I}$. 

Then it is easily checked by definition that the intersection of all these $\sigma$-algebras (which is obviously the smallest), is itself a $\sigma$-algebra.

\begin{align*}
\mathscr{A} = \bigcap_{\alpha \in I} \mathscr{A}_\alpha
\end{align*}
\end{proof}
\end{theorem}

Hence given any collection of subsets for a given space, we can form a $\sigma$-algebra. There is a very important special case in which we do this all the time:

\begin{definition}
Let $(X,\mathcal{O})$ be a topological space. Then the smallest $\sigma$-algebra containing the sets in $\mathcal{O}$ (often called the open sets in $X$) is called the Borel $\sigma$-algebra.
\end{definition}

\begin{definition}
Suppose $\mu$ is a measure on $X$. Let $f:X\to\mathbb{R}$ be a function from $X$ into $\mathbb{R}$. Then $f$ as a function is called $\mu-$measurable if for all $\alpha \in \mathbb{R}$ we have the preimage of the interval $(\alpha,\infty)$, denoted $f^{-1}((\alpha,\infty))$ is a $\mu-$measurable set. 
\end{definition}

\begin{remark}
In the above case, $f^{-1}(A)$ where $A$ is a set in $\mathbb{R}$ is called the ``preimage of $A$ under $f$" and is the set of all points in the domain that map through $f$ into $A$. That is to say, $f^{-1}(A) = \{x \in X : f(x) \in A\}$. This is not the same as the inverse function of $f$. 
\end{remark}

\begin{theorem}[Egoroff]
Let $\mu$ be an outer measure on $X$ and let $A$ be $\mu-$measurable with finite measure $\mu(A) < \infty$. If $f_1, f_2, \ldots$ is a sequence of $\mu-$measurable functions $f_k: A \to \mathbb{R}$ with $\lim\limits_{k \to \infty} f_k(x) = 0$ for all $x \in A$, then for every $\varepsilon > 0$ there exists $B \subseteq A$ with $\mu(A \setminus B) < \varepsilon$ and $f_k(x) \to 0$ uniformly on $B$. 
\end{theorem}

Remarkably, Egoroff's theorem says that if you have pointwise convergence, you can throw away a set of arbitrarily small measure to get uniform convergence. This is particularly useful for us, as in measure theory theorems often are stated as holding ``almost everywhere" (a.e.) meaning up to a possible set of measure 0, where the statement may not hold.

\begin{remark}
Regarding the theorem above:
\begin{enumerate}
\item When we say $\lim\limits_{k \to \infty} f_k = 0$, this is merely to save space, it is equivalent to say that there exists a limiting function $f$ for which $\lim\limits_{k \to \infty} f_k = f$, we merely subtracted $f$ from both sides and spoke about the new function $f_k - f$, thus eliminating the need to mention $f$ at all. This is common shorthand and will not be mentioned again.
\item Uniform convergence is much stronger than pointwise convergence, in that the sequence of functions must approach the limiting function in such a way that the values convergence for all $x$ in the domain simultaneously (in a tube-like fashion). Pointwise convergence merely means that looking at any particular point, the value of the sequence at that point converges to the limit.
\end{enumerate}
\end{remark}

We will now attempt to convince ourselves that Carath\'eodory's definition of a measurable set is a good one in the sense that it leads to powerful measures with lots of measurable sets in a general setting.

\begin{definition}
Let $X$ be a topological space. A measure $\mu$ on $X$ is Borel regular if:

\begin{enumerate}
\item All Borel sets are $\mu$-measurable. (All of the sets in the Borel $\sigma$-algebra)
\item For every set $A \subseteq X$ there exists a borel set $A \subseteq B$ with $\mu(B) = \mu(A)$
\end{enumerate}
\end{definition}

\begin{remark}
It is a common mistake to assume that because $\mu(B) = \mu(A)$ that $\mu(B \setminus A) = 0$. But this is only true under certain circumstances. Suppose $A$ is measurable, that implies $\mu(B) = \mu(B \setminus A) + \mu(B \cap A)$ by the definition of measurability. Since $A \subseteq B$ we have that $B \cap A = A$ and thus $\mu(B) = \mu(B \setminus A) + \mu(A)$, one may be tempted to conclude from this that $\mu(B \setminus A) = 0$, but because we allow measures to be infinite, we cannot simply subtract $\mu(A)$ from both sides lest we get $\infty - \infty$ which is left undefined. Thus we must assume that $A$ is measurable and $\mu(A) < \infty$ to conclude $\mu(B \setminus A) = 0$.
\end{remark}

\begin{theorem}[Carath\'eodory's Theorem]
Let $X$ be a metric space and $\mu$ be any outer measure on $X$ such that $\mu(A \cup B) = \mu(A) + \mu(B)$ whenever $d(A,B) > 0$. Then
\end{theorem}

\begin{remark}
If $d(a,b)$ is the distance between two points then we define the distance between two sets of points $d(A,B) = \inf \{d(a,b) : a \in A, b \in B\}$ then all Borel sets in the Borel $\sigma$-algebra generated by the open balls under $d$ are $\mu$-measurable.
\end{remark}

The assumption above is satisfied for many reasonable measures, intuitively because if the sets are separated by some distance then they shouldn't have any overlap - thus their measures should simply add.

\subsection{Integration, Generalized}

\subsection{Hausdorff Measures}

Hausdorff measures are some of the monst important measures we have in Geometric Measure Theory and provide not only a reasonable notion of length, area, and volumes but also dimension in a very general way. Their definition will be in two parts.

\begin{definition}
Let $X$ be a metric space. Define the diameter of a set $A$ to be $\text{diam}(A) = \sup\{d(x,y) : x,y \in A\}$. For any set $S \subseteq X$ and any real numbers $k, \delta \geq 0$, define the $k$-dimensional measure of $S$ by sets of diameter $\leq \delta$ by:

\begin{align*}
\mathcal{H}_\delta^k(S) :=  \inf \left\{ \sum_j \frac{\omega_k \cdot \text{diam}(E_j)^k}{2^k} : S \subseteq \bigcup_j E_j, \text{diam}(E_j) \leq \delta \right\}
\end{align*}

Where the infimum is taken over all countable covers $S \supseteq \bigcup\limits_j E_j$ constrained so that each set $E_j$ has a diameter at most $\delta$. $\omega_k$ is the volume of the unit $k$-dimensional ball. 
\end{definition}

The value of our dimensional constant is $\omega_k := \frac{2^k \pi^{k/2}}{\Gamma(\frac{k}{2}+1)}$, where $\Gamma$ denotes the gamma function. This constant is chosen so that our measure agrees with intuitive convention.

The above definition may seem quite complex at first, but it is quite simple and natural. Suppose that you are given some flat shape and you want to measure its area, but all you have are post-it notes of varying sizes. One thing you can do is to try to cover the object with the post it notes and then add up the areas of each note. (Of course in the mathematical definition, your post-it notes can be of any shape but of size no more than $\delta$) One thing you will notice if you do this, is that when you use smaller post it notes (make $\delta$ smaller) your approximation increases in accuracy (perhaps at the cost of the work of covering the object in more and more notes), and if you use small enough notes you will cover the object nearly perfectly. Hence:

\begin{definition}
Let $S$ be a subset of a metric space $X$. We define the $k$-dimensional Hausdorff measure of $S$ by:
\begin{align*}
\mathcal{H}^k(S) := \lim_{\delta \to 0} \mathcal{H}^k_\delta (S)
\end{align*}
\end{definition}

\begin{example}
When $k = 0$, we have that the $0$ dimensional Hausdorff measure of a set $S$, $\mathcal{H}^0(S)$ defined above is nothing more than the number of points in the set. If there is an infinite number of points, $\mathcal{H}^0(S) = \infty$.
\end{example}

In a sense, $\delta$ is the sort of resolution at which we are looking at the set to measure. Imagine we wish to measure an infinite spiral $S$. We know intuitively that the spiral should have infinite length, so it should be that $\mathcal{H}^1(S) = \infty$; but imagine we try to measure it by covering it with sets of some diameter $\varepsilon > 0$; we would necessarily cover up too much of the tail and get a finite number for $\mathcal{H}^1(S)$. Hence the reason why we need to look at the limiting value as $\delta \to 0$. 

Thus far we've talked about a notion of dimension $k$, and we know how to (at least implicitly) calculate the $k$-dimensional Hausdorff measure for a given set. But this gives rise to the question; which $k$ should I use to measure a given set I'm interested in? Will the answer change if I choose ``incorrectly"? This leads us to the derived notion of Hausdorff dimension.

\begin{definition}
Let $X$ be a metric space and $S \subseteq X$. Define:

\begin{align*}
\mathcal{H}\text{-dim}(S) := \sup \left\{ k \geq 0 : \mathcal{H}^k(S) < \infty \right\}
\end{align*}

Or equivalently

\begin{align*}
\mathcal{H}\text{-dim}(S) :=  \inf \left\{ k \geq 0 : \mathcal{H}^k(S) = \infty \right\}
\end{align*}
\end{definition}

The above is always defined for any set $S$. What this tells us is that there is that given a set $S$, there is a unique value of $k$ that is a sort of Goldilocks number. Suppose we're trying to measure the area of a piece of paper. If we use a $k = 1$ dimensional measure, then we are trying to essentially cover the paper with 1 dimensional sets - i.e. infinitely thin lines. Since we will need an infinite number of these lines to cover the page, we'll get a 1-dimensional measure of $\infty$. Suppose that we try to measure the piece of paper using a $k = 3$ dimensional measure, covering it with something like tennis balls or cubes. No matter what we choose, the piece of paper will only occupy an infinitely thin slice of the 3d object - hence its $k=3$ measure will be 0. In this case, the Goldilocks value of $k$ to use will be 2 - we can again use something like sticky notes to cover the piece of paper and figure out a reasonable idea of what its measure is. 

More precisely, there is some value of $k$ where $\mathcal{H}^k(S)$ flips from being $\infty$ to 0, measuring with sets of too small dimension to too big of dimension. This value of $k$ where it flips is what we call the dimension of $S$.

\begin{remark}
Note that at $k = \mathcal{H}$-dim$(S)$ the set $S$ may still have measure of $0$ or $\infty$. Imagine measuring the empty set, or perhaps all of $\mathbb{R}^2$ for examples.
\end{remark}

\begin{example}
Show the cantor set has Hausdorff dimension $\frac{\log 2}{ \log 3}$
\end{example}

\subsection{Rectifiable Sets}

Consider $\mathbb{R}^n$ as a space equipped with the standard euclidean metric and topology inherited from it.

\begin{definition}
A Borel subset $S$ of $\mathbb{R}^n$ is called $k$-rectifiable if $S$ has Hausdorff dimension $k$ and there exists a countable collection of continuously differentiable maps:

\begin{align*}
f_i: \mathbb{R}^k \to \mathbb{R}^n
\end{align*}

such that:

\begin{align*}
\mathcal{H}^k\left( S \setminus \bigcup_{i=1}^\infty f_i (\mathbb{R}^k) \right) = 0
\end{align*}
\end{definition}

That is to say, a Borel subset in $\mathbb{R}^n$ is $k$-rectifiable if it is approximately pieces of $\mathbb{R}^k$ (approximately in the sense of up to a set of $\mathcal{H}^k$ measure 0), deformed in a continuously differentiable manner.

\begin{remark}
Some authors prefer to equivalently define rectifiable sets using Lipschitz maps instead of continuously differentiable ones.
\end{remark}

\begin{remark}
You can generalize the above notion to $(\mu,k)$-rectifiability where $\mu$ is any measure you want, simply replace $\mathcal{H}^k$ with $\mu$ in the definition. 
\end{remark}

Perhaps more intuitively, rectifiable sets may be thought of as generalizations of $k$-dimensional $C^1$-submanifolds. In the sense that they are countable unions of pieces of $k$-dimensional $C^1$-submanifolds (possibly with a measure 0 junk set) or of possessing approximate tangent spaces $\mathcal{H}^k$ almost everywhere.

We now seek to define these so-called approximate tangent spaces in terms of a procedure that ``blows-up" or ``zooms-in" at a point.

\begin{definition}
Let $S \subseteq \mathbb{R}^n$. Then a subspace $T$ of $\mathbb{R}^n$ is the approximate tangent space to $S$ at the point $p \in \mathbb{R}^n$ if for all compactly supported $f \in C_c(\mathbb{R}^n)$:

\begin{align*}
\lim_{\lambda \to 0^+} \int_{\eta_{p,\lambda}(S) } f(y) d\mathcal{H}^k(y) = \int_T f(y)d\mathcal{H}^k(y)
\end{align*}

Where $\eta_{p,\lambda}(y) := \frac{y-p}{\lambda}$.
\end{definition}

The above may look daunting, it's actually quite simple and very informative of what is going on. The map $\eta_{p,\lambda}(y)$ for $0 < \lambda < 1$ acts as a blow up by a factor of $\lambda$ for the set $S$ about the point $p$. The integrals against test functions is nothing more than the standard notion of weak convergence. Hence we say that $T$ is the tangent plane of $S$ at $p$ if we have weak convergence of the identity $1$ over the blow up of $S$ at $p$ to the identity over $T$ as $\lambda \to 0^+$. Even more simply, when we zoom in on the point $p$, our set $S$ approximately looks like $T$.

\subsection{Currents}

\subsection{The Flat Norm}



\section{L1TV Computes the Flat Norm}

\section{Answers and Questions}

\section{Computing the Flat Norm}

\end{document}
